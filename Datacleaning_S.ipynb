{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec194045",
      "metadata": {
        "id": "ec194045"
      },
      "outputs": [],
      "source": [
        "# import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb201207",
      "metadata": {
        "id": "bb201207"
      },
      "source": [
        "## 1) Load the messy dataset (with headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ce1f57",
      "metadata": {
        "id": "71ce1f57"
      },
      "outputs": [],
      "source": [
        "# messy_employee_health.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdb0adf1",
      "metadata": {
        "id": "bdb0adf1"
      },
      "source": [
        "## 2) Missing headers (use the no-header file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3efba1",
      "metadata": {
        "id": "ae3efba1"
      },
      "outputs": [],
      "source": [
        "# check the first first records\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a020fb5",
      "metadata": {
        "id": "0a020fb5"
      },
      "source": [
        "## 3) Missing values\n",
        "Compute missing counts and percentages. Then choose a strategy (drop, fill, impute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccdf249e",
      "metadata": {
        "id": "ccdf249e"
      },
      "outputs": [],
      "source": [
        "# drop the missing values\n",
        "\n",
        "\n",
        "# fill the missing values with average\n",
        "\n",
        "\n",
        "# impute the values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be59322b",
      "metadata": {
        "id": "be59322b"
      },
      "source": [
        "## 4) Empty rows and empty columns\n",
        "Identify and remove completely empty rows and columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95975545",
      "metadata": {
        "id": "95975545"
      },
      "outputs": [],
      "source": [
        "# TODO: find empty rows\n",
        "\n",
        "# TODO: drop empty rows\n",
        "\n",
        "\n",
        "# TODO: find empty columns\n",
        "\n",
        "\n",
        "# TODO: drop empty columns\n",
        "\n",
        "# df_step.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809c021c",
      "metadata": {
        "id": "809c021c"
      },
      "source": [
        "## 5) Messy column names\n",
        "Standardize: strip, lowercase, underscores, remove special chars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9335a77",
      "metadata": {
        "id": "d9335a77"
      },
      "outputs": [],
      "source": [
        "# TODO: clean column names\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d939a6f",
      "metadata": {
        "id": "6d939a6f"
      },
      "source": [
        "## 6) Multiple variables in one column (Heart Rate)\n",
        "Extract numeric heart rate (bpm) as an integer. Handle values like `85bpm`, `100 BPM`, `??`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44e4dd9",
      "metadata": {
        "id": "e44e4dd9"
      },
      "outputs": [],
      "source": [
        "# TODO: normalize heart_rate strings then extract digits\n",
        "# df_step['heart_rate'] = ...\n",
        "# df_step['heart_rate_bpm'] = ...\n",
        "\n",
        "# df_step[['heart_rate', 'heart_rate_bpm']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed61b4b0",
      "metadata": {
        "id": "ed61b4b0"
      },
      "source": [
        "## 7) Inconsistent units (Height)\n",
        "Convert height to meters (float). Handle `170 cm`, `1.75 m`, `180cm`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce38c60",
      "metadata": {
        "id": "4ce38c60"
      },
      "outputs": [],
      "source": [
        "# TODO: create height_m\n",
        "# df_step['height_m'] = ...\n",
        "\n",
        "# df_step[['height', 'height_m']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146b90a6",
      "metadata": {
        "id": "146b90a6"
      },
      "source": [
        "## 8) Capitalization + typos in categorical values (Gender)\n",
        "Standardize gender values and fix typos like `Mle`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b668c4cc",
      "metadata": {
        "id": "b668c4cc"
      },
      "outputs": [],
      "source": [
        "# TODO: normalize gender\n",
        "# df_step['gender'] = ...\n",
        "\n",
        "# df_step['gender'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aa0ad71",
      "metadata": {
        "id": "7aa0ad71"
      },
      "source": [
        "## 9) Data types (Age, IDs)\n",
        "Convert `id` to integer (nullable ok), `age` to numeric; identify invalid values (e.g., negative age)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19cfc5d",
      "metadata": {
        "id": "d19cfc5d"
      },
      "outputs": [],
      "source": [
        "# TODO: convert types\n",
        "# df_step['id'] = ...\n",
        "# df_step['age'] = ...\n",
        "\n",
        "# TODO: find invalid ages\n",
        "# df_step[(df_step['age'] < 0) | (df_step['age'] > 100)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c39fe5",
      "metadata": {
        "id": "b1c39fe5"
      },
      "source": [
        "## 10) Addresses\n",
        "Split address into street, city, and pincode. Handle missing parts safely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce70c11",
      "metadata": {
        "id": "dce70c11"
      },
      "outputs": [],
      "source": [
        "# TODO: split address by comma into 3 parts\n",
        "# addr = df_step['address'].str.split(',', n=2, expand=True)\n",
        "# df_step['street'] = ...\n",
        "# df_step['city'] = ...\n",
        "# df_step['pincode'] = ...\n",
        "\n",
        "# df_step[['address','street','city','pincode']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1ef71e",
      "metadata": {
        "id": "fc1ef71e"
      },
      "source": [
        "## 11) Dates\n",
        "Parse join_date with mixed formats and coerce invalid dates to NaT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aef5dcd",
      "metadata": {
        "id": "8aef5dcd"
      },
      "outputs": [],
      "source": [
        "# TODO: parse dates\n",
        "# df_step['join_date'] = pd.to_datetime(df_step['join_date'], errors='coerce', dayfirst=True)\n",
        "# df_step[['join_date']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a66f0d5",
      "metadata": {
        "id": "7a66f0d5"
      },
      "source": [
        "## 12) Non-ASCII characters (Notes)\n",
        "Remove non-ASCII characters OR normalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315a1e20",
      "metadata": {
        "id": "315a1e20"
      },
      "outputs": [],
      "source": [
        "# TODO: remove non-ascii\n",
        "# df_step['notes_clean'] = ...\n",
        "# df_step[['notes','notes_clean']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afdbb234",
      "metadata": {
        "id": "afdbb234"
      },
      "source": [
        "## 13) Unnecessary data\n",
        "Remove duplicate rows, irrelevant columns, and uninformative columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c407093",
      "metadata": {
        "id": "7c407093"
      },
      "outputs": [],
      "source": [
        "# TODO: duplicates\n",
        "# df_step.duplicated().sum()\n",
        "# df_step = df_step.drop_duplicates()\n",
        "\n",
        "# TODO: drop irrelevant columns\n",
        "# df_step = df_step.drop(columns=['irrelevant_column'], errors='ignore')\n",
        "\n",
        "# TODO: drop uninformative columns (nunique == 1)\n",
        "# nun = df_step.nunique(dropna=False)\n",
        "# drop_cols = nun[nun == 1].index\n",
        "# df_step = df_step.drop(columns=drop_cols)\n",
        "\n",
        "# df_step.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f4b528",
      "metadata": {
        "id": "27f4b528"
      },
      "source": [
        "## 14) Final cleaned dataset\n",
        "Show summary and export as CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8aa4374",
      "metadata": {
        "id": "d8aa4374"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}